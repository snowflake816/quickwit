// Copyright (C) 2023 Quickwit, Inc.
//
// Quickwit is offered under the AGPL v3.0 and as commercial software.
// For commercial licensing, contact us at hello@quickwit.io.
//
// AGPL:
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see <http://www.gnu.org/licenses/>.

syntax = "proto3";

package quickwit.metastore;

import "quickwit/ingest.proto";

enum SourceType {
  SOURCE_TYPE_UNSPECIFIED = 0;
  SOURCE_TYPE_CLI = 1;
  SOURCE_TYPE_FILE = 2;
  SOURCE_TYPE_GCP_PUBSUB = 3;
  SOURCE_TYPE_INGEST_V1 = 4;
  SOURCE_TYPE_INGEST_V2 = 5;
  SOURCE_TYPE_KAFKA = 6;
  SOURCE_TYPE_KINESIS = 7;
  SOURCE_TYPE_NATS = 8;
  SOURCE_TYPE_PULSAR = 9;
  SOURCE_TYPE_VEC = 10;
  SOURCE_TYPE_VOID = 11;
}

// Metastore meant to manage Quickwit's indexes, their splits and delete tasks.
//
// I. Index and splits management.
//
// Quickwit needs a way to ensure that we can cleanup unused files,
// and this process needs to be resilient to any fail-stop failures.
// We rely on atomically transitioning the status of splits.
//
// The split state goes through the following life cycle:
// 1. `Staged`
//   - Start uploading the split files.
// 2. `Published`
//   - Uploading the split files is complete and the split is searchable.
// 3. `MarkedForDeletion`
//   - Mark the split for deletion.
//
// If a split has a file in the storage, it MUST be registered in the metastore,
// and its state can be as follows:
// - `Staged`: The split is almost ready. Some of its files may have been uploaded in the storage.
// - `Published`: The split is ready and published.
// - `MarkedForDeletion`: The split is marked for deletion.
//
// Before creating any file, we need to stage the split. If there is a failure, upon recovery, we
// schedule for deletion all the staged splits. A client may not necessarily remove files from
// storage right after marking it for deletion. A CLI client may delete files right away, but a
// more serious deployment should probably only delete those files after a grace period so that the
// running search queries can complete.
//
// II. Delete tasks management.
//
// A delete task is defined on a given index and by a search query. It can be
// applied to all the splits of the index.
//
// Quickwit needs a way to track that a delete task has been applied to a split. This is ensured
// by two mechanisms:
// - On creation of a delete task, we give to the task a monotically increasing opstamp (uniqueness
//   and monotonically increasing must be true at the index level).
// - When a delete task is executed on a split, that is when the documents matched by the search
//   query are removed from the splits, we update the split's `delete_opstamp` to the value of the
//   task's opstamp. This marks the split as "up-to-date" regarding this delete task. If new delete
//   tasks are added, we will know that we need to run these delete tasks on the splits as its
//   `delete_optstamp` will be inferior to the `opstamp` of the new tasks.
//
// For splits created after a given delete task, Quickwit's indexing ensures that these splits
// are created with a `delete_opstamp` equal the latest opstamp of the tasks of the
// corresponding index.
service MetastoreService {
  // Creates an index.
  //
  // This API creates a new index in the metastore.
  // An error will occur if an index that already exists in the storage is specified.
  rpc CreateIndex(CreateIndexRequest) returns (CreateIndexResponse);

  // Returns the `IndexMetadata` of an index identified by its IndexID or its IndexUID.
  rpc IndexMetadata(IndexMetadataRequest) returns (IndexMetadataResponse);

  // Gets an indexes metadatas.
  rpc ListIndexesMetadata(ListIndexesMetadataRequest) returns (ListIndexesMetadataResponse);

  // Deletes an index
  rpc DeleteIndex(DeleteIndexRequest) returns (EmptyResponse);

  // Gets splits from index.
  rpc ListSplits(ListSplitsRequest) returns (ListSplitsResponse);

  // Stages several splits.
  rpc StageSplits(StageSplitsRequest) returns (EmptyResponse);

  // Publishes split.
  rpc PublishSplits(PublishSplitsRequest) returns (EmptyResponse);

  // Marks splits for deletion.
  rpc MarkSplitsForDeletion(MarkSplitsForDeletionRequest) returns (EmptyResponse);

  // Deletes splits.
  rpc DeleteSplits(DeleteSplitsRequest) returns (EmptyResponse);

  // Adds source.
  rpc AddSource(AddSourceRequest) returns (EmptyResponse);

  // Toggles source.
  rpc ToggleSource(ToggleSourceRequest) returns (EmptyResponse);

  // Removes source.
  rpc DeleteSource(DeleteSourceRequest) returns (EmptyResponse);

  // Resets source checkpoint.
  rpc ResetSourceCheckpoint(ResetSourceCheckpointRequest) returns (EmptyResponse);

  // Gets last opstamp for a given `index_id`.
  rpc LastDeleteOpstamp(LastDeleteOpstampRequest) returns (LastDeleteOpstampResponse);

  // Creates a delete task.
  rpc CreateDeleteTask(DeleteQuery) returns (DeleteTask);

  // Updates splits `delete_opstamp`.
  rpc UpdateSplitsDeleteOpstamp(UpdateSplitsDeleteOpstampRequest) returns (UpdateSplitsDeleteOpstampResponse);

  // Lists delete tasks with `delete_task.opstamp` > `opstamp_start` for a given `index_id`.
  rpc ListDeleteTasks(ListDeleteTasksRequest) returns (ListDeleteTasksResponse);

  // Lists splits with `split.delete_opstamp` < `delete_opstamp` for a given `index_id`.
  rpc ListStaleSplits(ListStaleSplitsRequest) returns (ListSplitsResponse);

  // Shard API
  //
  // Note that for the file-backed metastore implementation, the requests are not processed atomically.
  // Indeed, each request comprises one or more subrequests that target different indexes and sources processed
  // independently. Responses list the requests that succeeded or failed in the fields `successes` and
  // `failures`.
  rpc OpenShards(OpenShardsRequest) returns (OpenShardsResponse);

  // Acquires a set of shards for indexing. This RPC locks the shards for publishing thanks to a publish token and only
  // the last indexer that has acquired the shards is allowed to publish. The response returns for each subrequest the
  // list of acquired shards along with the positions to index from.
  rpc AcquireShards(AcquireShardsRequest) returns (AcquireShardsResponse);

  rpc DeleteShards(DeleteShardsRequest) returns (DeleteShardsResponse);

  rpc ListShards(ListShardsRequest) returns (ListShardsResponse);
}

message EmptyResponse {
}

message CreateIndexRequest {
  string index_config_json = 2;
}

message CreateIndexResponse {
  string index_uid = 1;
}

message ListIndexesMetadataRequest {
  reserved  1;
  repeated string index_id_patterns = 2;
}

message ListIndexesMetadataResponse {
  string indexes_metadata_serialized_json = 1;
}

message DeleteIndexRequest {
  string index_uid = 1;
}

// Request the metadata of an index.
// Either `index_uid` or `index_id` must be specified.
//
// If both are supplied, `index_uid` is used.
message IndexMetadataRequest {
  optional string index_id = 1;
  optional string index_uid = 2;
}

message IndexMetadataResponse {
  string index_metadata_serialized_json = 1;
}

message ListSplitsRequest {
  // Predicate used to filter splits.
  // The predicate is expressed as a JSON serialized
  // `ListSplitsQuery`.
  string query_json = 1;
}

message ListSplitsResponse {
  // TODO use repeated and encode splits json individually.
  string splits_serialized_json = 1;
}

message StageSplitsRequest {
  string index_uid = 1;
  string split_metadata_list_serialized_json = 2;
}

message PublishSplitsRequest {
  string index_uid = 1;
  repeated string staged_split_ids = 2;
  repeated string replaced_split_ids = 3;
  optional string index_checkpoint_delta_json_opt = 4;
  optional string publish_token_opt = 5;
}

message MarkSplitsForDeletionRequest {
  string index_uid = 2;
  repeated string split_ids = 3;
}

message DeleteSplitsRequest {
  string index_uid = 2;
  repeated string split_ids = 3;
}

message AddSourceRequest {
  string index_uid = 1;
  string source_config_json = 2;
}

message ToggleSourceRequest {
  string index_uid = 1;
  string source_id = 2;
  bool enable = 3;
}

message DeleteSourceRequest {
  string index_uid = 1;
  string source_id = 2;
}

message ResetSourceCheckpointRequest {
  string index_uid = 1;
  string source_id = 2;
}

//
// Delete tasks API.
//

message DeleteTask {
  int64 create_timestamp = 1;
  uint64 opstamp = 2;
  DeleteQuery delete_query = 3;
}

message DeleteQuery {
  // Index ID.
  string index_uid = 1;
  // If set, restrict search to documents with a `timestamp >= start_timestamp`.
  optional int64 start_timestamp = 2;
  // If set, restrict search to documents with a `timestamp < end_timestamp``.
  optional int64 end_timestamp = 3;
  // Query text. The query language is that of tantivy.
  // Query AST serialized in JSON
  string query_ast = 6;

  // Reserved field due to deprecation
  reserved 4, 5;
}

message UpdateSplitsDeleteOpstampRequest {
  string index_uid = 1;
  repeated string split_ids = 2;
  uint64 delete_opstamp = 3;
}

message UpdateSplitsDeleteOpstampResponse {}

message LastDeleteOpstampRequest {
  string index_uid = 1;
}

message LastDeleteOpstampResponse {
  uint64 last_delete_opstamp = 1;
}

message ListStaleSplitsRequest {
  string index_uid = 1;
  uint64 delete_opstamp = 2;
  uint64 num_splits = 3;
}

message ListDeleteTasksRequest {
  string index_uid = 1;
  uint64 opstamp_start = 2;
}

message ListDeleteTasksResponse {
  repeated DeleteTask delete_tasks = 1;
}

//
// Shard API
//

message OpenShardsRequest {
  repeated OpenShardsSubrequest subrequests = 1;
}

message OpenShardsSubrequest {
  uint32 subrequest_id = 1;
  string index_uid = 2;
  string source_id = 3;
  string leader_id = 4;
  optional string follower_id = 5;
  uint64 next_shard_id = 6;
}

message OpenShardsResponse {
  repeated OpenShardsSubresponse subresponses = 1;
}

message OpenShardsSubresponse {
  uint32 subrequest_id = 1;
  string index_uid = 2;
  string source_id = 3;
  repeated quickwit.ingest.Shard opened_shards = 4;
  uint64 next_shard_id = 5;
}

message AcquireShardsRequest {
  repeated AcquireShardsSubrequest subrequests = 1;
}

message AcquireShardsSubrequest {
  string index_uid = 1;
  string source_id = 2;
  repeated uint64 shard_ids = 3;
  string publish_token = 4;
}

message AcquireShardsResponse {
  repeated AcquireShardsSubresponse subresponses = 1;
}

message AcquireShardsSubresponse {
  string index_uid = 1;
  string source_id = 2;
  repeated quickwit.ingest.Shard acquired_shards = 3;
}

message DeleteShardsRequest {
  repeated DeleteShardsSubrequest subrequests = 1;
  // If false, only shards at EOF positions will be deleted.
  bool force = 2;
}

message DeleteShardsSubrequest {
  string index_uid = 1;
  string source_id = 2;
  repeated uint64 shard_ids = 3;
}

message DeleteShardsResponse {
}

message ListShardsRequest {
  repeated ListShardsSubrequest subrequests = 1;
}

message ListShardsSubrequest {
  string index_uid = 1;
  string source_id = 2;
  optional quickwit.ingest.ShardState shard_state = 3;
}

message ListShardsResponse {
  repeated ListShardsSubresponse subresponses = 1;
}

message ListShardsSubresponse {
  string index_uid = 1;
  string source_id = 2;
  repeated quickwit.ingest.Shard shards = 3;
  uint64 next_shard_id = 4;
}
